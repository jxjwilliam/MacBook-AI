
### 🥃 Claude Dev

🟢 专注于自动化任务和代码生成，尤其在复杂项目管理和代码分析方面表现突出。
🟢 主要优势在于能够执行一系列任务，如文件操作、终端命令、递归地搜索和编辑项目文件，以及利用链式思维逐步解决问题。
🟢 支持ollama以及第三方api

### 🥃 Cursor

🟢 Cursor可以直接在 IDE 中调用 AI 进行代码编写和调试，适合轻量级项目或者需要频繁人工交互的开发者。
🟠 缺点是无法使用ollama等本地模型，使用Claude api的话token消耗惊人。
🟠 使用Claude 3.5模型，同等token消耗，效果远不如Claude Dev。
🟠 bug多，对话历史会丢失。
🟠 只适合脚本语言等非复杂交互等项目

### 🥃 GitHub Models

🟢 GitHub Models 是一个能够帮助开发者直接在 GitHub 上使用 AI 模型的项目。
🟢 用户可以轻松地访问和实验多个生成式 AI 模型，如 Meta 的 LLaMA、GPT-4o、Phi-3 和 Mistral。
🟢 GitHub 提供了一个模型游乐场（playground），用户可以测试不同的提示、调整参数（如温度），并比较不同模型的输出结果。
🟢 该平台的核心目的是让开发者从实验到生产都能在熟悉的环境中操作。
🟢 用户可以通过 GitHub Codespaces 和 Visual Studio Code 将这些模型集成到自己的项目中，并使用 Azure 的 AI 服务进行部署。Azure 提供了企业级的安全性、可扩展性，确保模型能无缝地从实验环境过渡到生产环境。
🟢 GitHub Models 对所有用户开放，从学生到专业人士都可以使用，并提供了丰富的学习和实验工具。

### 🥃 

### 🥃 

### 🥃 Authentication: @Clerk/nextjs


### 🥃 

### 🥃 

### 🥃 

### 🥃 Make.com vs. Zapier vs. n8n

Automating workflows.

### 🥃 notion.so

### 🥃 vLLM vs. ollama vs. unsloth

- `vLLM` is primarily a high-performance serving engine for LLMs, focusing on optimizing `inference` speed and efficiency.
- `Unsloth` is a tool designed to optimize the `fine-tuning` process for LLMs, with a focus on speed and efficiency. Supports exporting to various formats (`GGUF`, `vLLM`)

| Feature                  | vLLM                   | Unsloth                | Ollama                |
|--------------------------|------------------------|------------------------|-----------------------|
| Primary Focus            | Inference speed        | Fine-tuning speed      | Local deployment       |
| Performance Optimization  | High (PagedAttention)  | Moderate (fine-tuning) | Moderate              |
| Ease of Use             | Moderate               | High                   | Very High             |
| Model Support            | Wide (HuggingFace)     | Focused (fine-tuning)  | Various open-source    |
| Deployment               | Cloud, on-premise      | Flexible               | Local                 |
| Integration              | HuggingFace, OpenAI API| HuggingFace            | Standalone            |

### 🥃 

### 🥃 Llama-Factory

- fastest way to fine tune models like Phi3 or Llama3 in less than 15 mins
- LLaMA, LLaVA, Unsloth, Qwen, Gradio UI

### 🥃 Learning LLM

- Gradio, Streamlit
- Pandas, Matplotlib
- Redis, PostgreSQL, MongoDB
- RESTful API, FastAPI, WebSocket, gRPC, webhook
- async, multi-progress, multi-threads
- Go, JS/TS, Rust
- AutoML, XGBoost, LightGBM, CatBoost, F1-score, CNN, LSTM, NLP
- Pytorch, TensorFlow 2.x, Keras
- Transformer, BERT, GPT
- LLaMA, ChatGLM, Qwen, OpenAI, LangChain
- Prompt Engineering, RAG, GraphRAG, llama.cpp, vLLM
- LLaMA-Factory, Fine Tuning, Embedded, LlamaIndex, Ollama
- Quantitation, LoRA
- Hugging Face (transformers, perf), ModelScope
- AI Agent, AI synthesis
- LMStudio, AnythingLLM, Open-WebUI
- Llama3.1, Mistral, Curor AI, Claude Dev


## 学习目标
具备大模型的训练与调优能力，能够开发和优化适用于特定领域的AI模型

### 从事岗位：AI大模型工程师（40K+）
1. 模型即服务共享平台  
2. 私有部署本地大模型  
3. 训练自己的大模型  
4. 大模型微调  

### 特定任务的模型微调训练
- 基于BERT的中文评价情感分析  
- 如何处理超长文本训练问题  
- GPT2-中文生成模型定制化微调训练  
- GPT2-中文生成模型定制化内容输出  
- LlaMA3大模型本地部署与调用  
- 使用自定义数据集和LLaMA-Factory完成LlaMA3微调训练  
- LlaMA3 LoRA微调测试评估、模型合并、量化  
- LoRA微调后的模型部署  

### 多模态大模型使用
- 多模态大模型基本概念  
- 本地部署CogVideoX-5B文生视频模型  
- Llama 3.2-Vision 模型架构剖析  
- Llama 3.2-Vision 模型预期用途  
- 使用ollama部署Llama 3.2-11B-Vision-Instruct，GGUF实现视觉问答  
