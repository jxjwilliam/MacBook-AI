
### ğŸ¥ƒ Claude Dev

ğŸŸ¢ ä¸“æ³¨äºè‡ªåŠ¨åŒ–ä»»åŠ¡å’Œä»£ç ç”Ÿæˆï¼Œå°¤å…¶åœ¨å¤æ‚é¡¹ç›®ç®¡ç†å’Œä»£ç åˆ†ææ–¹é¢è¡¨ç°çªå‡ºã€‚
ğŸŸ¢ ä¸»è¦ä¼˜åŠ¿åœ¨äºèƒ½å¤Ÿæ‰§è¡Œä¸€ç³»åˆ—ä»»åŠ¡ï¼Œå¦‚æ–‡ä»¶æ“ä½œã€ç»ˆç«¯å‘½ä»¤ã€é€’å½’åœ°æœç´¢å’Œç¼–è¾‘é¡¹ç›®æ–‡ä»¶ï¼Œä»¥åŠåˆ©ç”¨é“¾å¼æ€ç»´é€æ­¥è§£å†³é—®é¢˜ã€‚
ğŸŸ¢ æ”¯æŒollamaä»¥åŠç¬¬ä¸‰æ–¹api

### ğŸ¥ƒ Cursor

ğŸŸ¢ Cursorå¯ä»¥ç›´æ¥åœ¨ IDE ä¸­è°ƒç”¨ AI è¿›è¡Œä»£ç ç¼–å†™å’Œè°ƒè¯•ï¼Œé€‚åˆè½»é‡çº§é¡¹ç›®æˆ–è€…éœ€è¦é¢‘ç¹äººå·¥äº¤äº’çš„å¼€å‘è€…ã€‚
ğŸŸ  ç¼ºç‚¹æ˜¯æ— æ³•ä½¿ç”¨ollamaç­‰æœ¬åœ°æ¨¡å‹ï¼Œä½¿ç”¨Claude apiçš„è¯tokenæ¶ˆè€—æƒŠäººã€‚
ğŸŸ  ä½¿ç”¨Claude 3.5æ¨¡å‹ï¼ŒåŒç­‰tokenæ¶ˆè€—ï¼Œæ•ˆæœè¿œä¸å¦‚Claude Devã€‚
ğŸŸ  bugå¤šï¼Œå¯¹è¯å†å²ä¼šä¸¢å¤±ã€‚
ğŸŸ  åªé€‚åˆè„šæœ¬è¯­è¨€ç­‰éå¤æ‚äº¤äº’ç­‰é¡¹ç›®

### ğŸ¥ƒ GitHub Models

ğŸŸ¢ GitHub Models æ˜¯ä¸€ä¸ªèƒ½å¤Ÿå¸®åŠ©å¼€å‘è€…ç›´æ¥åœ¨ GitHub ä¸Šä½¿ç”¨ AI æ¨¡å‹çš„é¡¹ç›®ã€‚
ğŸŸ¢ ç”¨æˆ·å¯ä»¥è½»æ¾åœ°è®¿é—®å’Œå®éªŒå¤šä¸ªç”Ÿæˆå¼ AI æ¨¡å‹ï¼Œå¦‚ Meta çš„ LLaMAã€GPT-4oã€Phi-3 å’Œ Mistralã€‚
ğŸŸ¢ GitHub æä¾›äº†ä¸€ä¸ªæ¨¡å‹æ¸¸ä¹åœºï¼ˆplaygroundï¼‰ï¼Œç”¨æˆ·å¯ä»¥æµ‹è¯•ä¸åŒçš„æç¤ºã€è°ƒæ•´å‚æ•°ï¼ˆå¦‚æ¸©åº¦ï¼‰ï¼Œå¹¶æ¯”è¾ƒä¸åŒæ¨¡å‹çš„è¾“å‡ºç»“æœã€‚
ğŸŸ¢ è¯¥å¹³å°çš„æ ¸å¿ƒç›®çš„æ˜¯è®©å¼€å‘è€…ä»å®éªŒåˆ°ç”Ÿäº§éƒ½èƒ½åœ¨ç†Ÿæ‚‰çš„ç¯å¢ƒä¸­æ“ä½œã€‚
ğŸŸ¢ ç”¨æˆ·å¯ä»¥é€šè¿‡ GitHub Codespaces å’Œ Visual Studio Code å°†è¿™äº›æ¨¡å‹é›†æˆåˆ°è‡ªå·±çš„é¡¹ç›®ä¸­ï¼Œå¹¶ä½¿ç”¨ Azure çš„ AI æœåŠ¡è¿›è¡Œéƒ¨ç½²ã€‚Azure æä¾›äº†ä¼ä¸šçº§çš„å®‰å…¨æ€§ã€å¯æ‰©å±•æ€§ï¼Œç¡®ä¿æ¨¡å‹èƒ½æ— ç¼åœ°ä»å®éªŒç¯å¢ƒè¿‡æ¸¡åˆ°ç”Ÿäº§ç¯å¢ƒã€‚
ğŸŸ¢ GitHub Models å¯¹æ‰€æœ‰ç”¨æˆ·å¼€æ”¾ï¼Œä»å­¦ç”Ÿåˆ°ä¸“ä¸šäººå£«éƒ½å¯ä»¥ä½¿ç”¨ï¼Œå¹¶æä¾›äº†ä¸°å¯Œçš„å­¦ä¹ å’Œå®éªŒå·¥å…·ã€‚

### ğŸ¥ƒ 

### ğŸ¥ƒ 

### ğŸ¥ƒ Authentication: @Clerk/nextjs


### ğŸ¥ƒ 

### ğŸ¥ƒ 

### ğŸ¥ƒ 

### ğŸ¥ƒ Make.com vs. Zapier vs. n8n

Automating workflows.

### ğŸ¥ƒ notion.so

### ğŸ¥ƒ vLLM vs. ollama vs. unsloth

- `vLLM` is primarily a high-performance serving engine for LLMs, focusing on optimizing `inference` speed and efficiency.
- `Unsloth` is a tool designed to optimize the `fine-tuning` process for LLMs, with a focus on speed and efficiency. Supports exporting to various formats (`GGUF`, `vLLM`)

| Feature                  | vLLM                   | Unsloth                | Ollama                |
|--------------------------|------------------------|------------------------|-----------------------|
| Primary Focus            | Inference speed        | Fine-tuning speed      | Local deployment       |
| Performance Optimization  | High (PagedAttention)  | Moderate (fine-tuning) | Moderate              |
| Ease of Use             | Moderate               | High                   | Very High             |
| Model Support            | Wide (HuggingFace)     | Focused (fine-tuning)  | Various open-source    |
| Deployment               | Cloud, on-premise      | Flexible               | Local                 |
| Integration              | HuggingFace, OpenAI API| HuggingFace            | Standalone            |

### ğŸ¥ƒ 

### ğŸ¥ƒ Llama-Factory

- fastest way to fine tune models like Phi3 or Llama3 in less than 15 mins
- LLaMA, LLaVA, Unsloth, Qwen, Gradio UI

### ğŸ¥ƒ Learning LLM

- Gradio, Streamlit
- Pandas, Matplotlib
- Redis, PostgreSQL, MongoDB
- RESTful API, FastAPI, WebSocket, gRPC, webhook
- async, multi-progress, multi-threads
- Go, JS/TS, Rust
- AutoML, XGBoost, LightGBM, CatBoost, F1-score, CNN, LSTM, NLP
- Pytorch, TensorFlow 2.x, Keras
- Transformer, BERT, GPT
- LLaMA, ChatGLM, Qwen, OpenAI, LangChain
- Prompt Engineering, RAG, GraphRAG, llama.cpp, vLLM
- LLaMA-Factory, Fine Tuning, Embedded, LlamaIndex, Ollama
- Quantitation, LoRA
- Hugging Face (transformers, perf), ModelScope
- AI Agent, AI synthesis
- LMStudio, AnythingLLM, Open-WebUI
- Llama3.1, Mistral, Curor AI, Claude Dev


## å­¦ä¹ ç›®æ ‡
å…·å¤‡å¤§æ¨¡å‹çš„è®­ç»ƒä¸è°ƒä¼˜èƒ½åŠ›ï¼Œèƒ½å¤Ÿå¼€å‘å’Œä¼˜åŒ–é€‚ç”¨äºç‰¹å®šé¢†åŸŸçš„AIæ¨¡å‹

### ä»äº‹å²—ä½ï¼šAIå¤§æ¨¡å‹å·¥ç¨‹å¸ˆï¼ˆ40K+ï¼‰
1. æ¨¡å‹å³æœåŠ¡å…±äº«å¹³å°  
2. ç§æœ‰éƒ¨ç½²æœ¬åœ°å¤§æ¨¡å‹  
3. è®­ç»ƒè‡ªå·±çš„å¤§æ¨¡å‹  
4. å¤§æ¨¡å‹å¾®è°ƒ  

### ç‰¹å®šä»»åŠ¡çš„æ¨¡å‹å¾®è°ƒè®­ç»ƒ
- åŸºäºBERTçš„ä¸­æ–‡è¯„ä»·æƒ…æ„Ÿåˆ†æ  
- å¦‚ä½•å¤„ç†è¶…é•¿æ–‡æœ¬è®­ç»ƒé—®é¢˜  
- GPT2-ä¸­æ–‡ç”Ÿæˆæ¨¡å‹å®šåˆ¶åŒ–å¾®è°ƒè®­ç»ƒ  
- GPT2-ä¸­æ–‡ç”Ÿæˆæ¨¡å‹å®šåˆ¶åŒ–å†…å®¹è¾“å‡º  
- LlaMA3å¤§æ¨¡å‹æœ¬åœ°éƒ¨ç½²ä¸è°ƒç”¨  
- ä½¿ç”¨è‡ªå®šä¹‰æ•°æ®é›†å’ŒLLaMA-Factoryå®ŒæˆLlaMA3å¾®è°ƒè®­ç»ƒ  
- LlaMA3 LoRAå¾®è°ƒæµ‹è¯•è¯„ä¼°ã€æ¨¡å‹åˆå¹¶ã€é‡åŒ–  
- LoRAå¾®è°ƒåçš„æ¨¡å‹éƒ¨ç½²  

### å¤šæ¨¡æ€å¤§æ¨¡å‹ä½¿ç”¨
- å¤šæ¨¡æ€å¤§æ¨¡å‹åŸºæœ¬æ¦‚å¿µ  
- æœ¬åœ°éƒ¨ç½²CogVideoX-5Bæ–‡ç”Ÿè§†é¢‘æ¨¡å‹  
- Llama 3.2-Vision æ¨¡å‹æ¶æ„å‰–æ  
- Llama 3.2-Vision æ¨¡å‹é¢„æœŸç”¨é€”  
- ä½¿ç”¨ollamaéƒ¨ç½²Llama 3.2-11B-Vision-Instructï¼ŒGGUFå®ç°è§†è§‰é—®ç­”  
