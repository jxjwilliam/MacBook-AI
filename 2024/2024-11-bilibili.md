## ğŸ¥ƒ 1. AI development practise

- AIåº”ç”¨å¼€å‘ï¼šå°†å·²æœ‰çš„ç®—æ³•è¿›è¡Œè½åœ°åŠåº”ç”¨ å‚è€ƒ llama.cpp, llama-factory, vllm

### ğŸ¥ƒ AI project

- configs: é…ç½®æ–‡ä»¶
- src: æ ¸å¿ƒä»£ç æ–‡ä»¶
- tools: ç‹¬ç«‹çš„æ‰§è¡ŒåŠŸèƒ½
- utils: å¤šä¸ªæ¨¡å—å¯å¤ç”¨çš„åŠŸèƒ½
- scripts: ä¸€é”®è„šæœ¬ï¼ˆå¯åŠ¨ã€åœæ­¢ã€æ‰“åŒ…ï¼‰
- assets: é¡¹ç›®ç›¸å…³èµ„æº (logo)
- resources: è®­ç»ƒæ•°æ® (raw)
- data: è®­ç»ƒæ•°æ® (formatted data for train)
- docs: è¯´æ˜æ–‡æ¡£
- weights: æ¨¡å‹æƒé‡
- logs: é¡¹ç›®è¿è¡Œæ—¥å¿—ï¼Œæ¨¡å‹è®­ç»ƒæ—¥å¿—
- readme.md: è¯´æ˜æ–‡ä»¶
- Dockerfiles: Docker é…ç½®æ–‡ä»¶
- requirements.txt: Python å®‰è£…åº“

### ğŸ¥ƒ AI Dev Env

```mermaid
flowchart TD
    subgraph LOCAL
        A[MAC]
        B[MAC]
    end

    subgraph REMOTE
        C[dev cluster: 4 x 4090<br>linux ubuntu]
        D[training cluster: 16 x A100<br>linux ubuntu]
    end

    A -- ssh --> C
    B -- ssh --> D
    B -. ssh .-> C

    %% Notes Section
    E["Notes:
    1. èµ„æºåˆç†åŒ–é…ç½®
    2. è§£å†³ç¯å¢ƒä¸ä¸€è‡´é—®é¢˜
    3. æ–¹ä¾¿å¤šäººåä½œ"]
```

### ğŸ¥ƒ example: [å¬èˆ’](https://github.com/echonoshy/tingshu)

## ğŸ¥ƒ 2. How to Use AI to Develop Large-Scale Software

## ğŸ¥ƒ 

## ğŸ¥ƒ Nvidia Series (Edge)


| Feature            | RTX 4090                         | A100                              | H100                              | H200                              |
|--------------------|----------------------------------|-----------------------------------|-----------------------------------|-----------------------------------|
| **Architecture**   | Ada Lovelace                     | Ampere                            | Hopper                            | Hopper                            |
| **CUDA Cores**     | 16,384                           | 8,192                             | 10,240                            | 12,288                            |
| **Memory**         | 24 GB GDDR6X                     | 40 GB HBM2                        | 80 GB HBM3                        | 120 GB HBM3                       |
| **Memory Bandwidth**| 1 TB/s                          | 1.6 TB/s                          | 3.2 TB/s                          | 4.8 TB/s                          |
| **TDP**            | 450 W                            | 250 W                             | 350 W                             | 500 W                             |
| **Release Date**   | September 2022                   | April 2020                        | Expected 2024                     | Expected 2025                     |
| **Target Market**  | High-end gaming, AI              | AI, HPC                           | AI, HPC                           | AI, HPC                           |


## ğŸ¥ƒ Nvidia Series (Perplexity)


| Feature                   | NVIDIA RTX 4090          | NVIDIA A100 (80 GB)     | NVIDIA H100 (80 GB)     | NVIDIA H200              |
|---------------------------|--------------------------|--------------------------|--------------------------|--------------------------|
| Architecture              | Ada Lovelace             | Ampere                   | Hopper                   | Hopper                   |
| Launch Date               | October 12, 2022        | June 22, 2020            | March 21, 2023          | Expected Q2 2024        |
| CUDA Cores                | 16,384                   | 6,912                    | 16,896                   | TBD                      |
| Memory Type               | GDDR6X                   | HBM2e                    | HBM3e                   | HBM3e                   |
| Memory Size               | 24 GB                    | 80 GB                    | 80 GB                    | 141 GB                  |
| Memory Bandwidth          | 1,018 GB/s               | 2,039 GB/s               | 3,039 GB/s               | 4,800 GB/s              |
| FP16 Performance (TFLOPS) | ~82.6                    | ~78                      | ~204.9                   | TBD                      |
| FP32 Performance (TFLOPS) | ~82.6                    | ~19.5                    | ~51.2                    | TBD                      |
| FP64 Performance (TFLOPS) | ~1.3                     | ~9.7                     | ~25.6                    | TBD                      |
| TDP                       | 450 W                    | 250 W                    | 350 W                    | ~700 W                  |
| Die Size                  | 608 mmÂ²                  | 826 mmÂ²                  | 814 mmÂ²                  | TBD                      |


## ğŸ¥ƒ 

## ğŸ¥ƒ 

## ğŸ¥ƒ 