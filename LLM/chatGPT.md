
## 🤖 🥃 ChatGPT Token

`ChatGPT` Token是指`ChatGPT`模型使用的一种标记或符号。在自然语言处理中，文本通常被分割成较小的单词、字符或子词来处理。`ChatGPT`使用的是基于字节对编码（Byte Pair Encoding，BPE）的标记化方法，将句子中的连续字符序列切割成不同的token。每个token代表了模型可以处理的最小单位，可以是一个单词、一个词根、一个字符或者其他更小的单位。

使用token作为输入是因为计算机在处理文本时需要将其转化为数值表示。通过将文本转化为token的序列，模型可以更好地理解和处理文本。Token的数量和顺序会影响模型的输入和输出。在`ChatGPT`中，输入的token序列用于构建上下文，而生成的token序列则用于生成响应。

在与`ChatGPT`交互时，用户的输入和模型的响应都会被分解成token，以便进行处理。同时，每个token都有一个对应的编号，用于在模型中进行索引和表示。

## 🤖 🥃 AIPRM (Artificial Intelligence Public Relations Management)

`AIPRM`是一个提示管理工具和社区驱动的提示库。它是一个浏览器扩展插件，可以为`ChatGPT`添加一个易于使用的策划提示模板列表，**专为SEO、营销、文案、生产力等需求设计**。这些提示是由一个由各领域专家组成的社区来精心策划的。只需点击一下，就可以访问精心挑选的`ChatGPT`提示，这些提示专门为营销人员、SEO、销售、客户支持、文案等设计。

`AIPRM`可以帮助你节省时间，提高工作质量，并从人工智能提示中获得更多价值信息³。你还可以创建自定义的人工智能提示，以满足特定需求。此外，它还允许你调整AI的语气和写作风格。

Whether you're a marketer looking to improve your SEO write-ups or a developer with no marketing knowledge wanting to promote your product, AIPRM can help. This is a small extension that's also user-friendly and can populate dozens of prompts on your dashboard – perfect for inspiration if you feel stuck as well.

## 🤖 🥃 Llama 2

`LlaMA 2` 是一个由 Meta 开发的大型语言模型，是 LLaMA 1 的继任者。`LlaMA 2` 可通过 AWS、Hugging Face 获取，并可以自由用于研究和商业用途。`LlaMA 2` 预训练模型在 2 万亿个标记上进行训练，相比 LLaMA 1 的上下文长度增加了一倍。 `LlaMA 2` is a second-generation open-source large language model (LLM) from Meta.

`LlaMA 2` 在包括推理、编码、精通性和知识测试等许多外部基准测试中都优于其他开源语言模型。`LlaMA 2` 的训练语料库包含了来自公开可用资源的混合数据，并且不包括 Meta 产品或服务相关的数据。

`Llama` is a term used in the context of GPT to refer to a specific type of language model that is trained on a **local** dataset, as opposed to a **global** dataset.

## 🤖 🥃 LlaMA 2 vs. LangChain vs localGPT

`LlaMA 2` 是一个强大的语言模型，可以用于各种 NLP 任务，而 LangChain 则是一个框架，可以帮助开发人员更容易地使用这些模型来构建复杂的应用程序

## 🤖 🥃 Privary information in ChatGPT conversation

**ChatGPT**: I am designed to forget information after the conversation ends, and I don't have the ability to `retain` or `recall` any personal data shared with me. **Each conversation is treated as a separate session**.

## 🤖 🥃  Is it safe to share company based information, such as logs, server information, codes in a chatGPT conversation?

1. **Data Handling by OpenAI**: `As of my last update in September 2021, OpenAI retains user input data for 30 days, but it no longer uses the data sent via the API to improve its models`.
2. Anonymity of Interaction.
3. Accidental Data Leaks.
4. No Guarantee of Complete Security.
5. Potential for Misunderstanding.

## 🤖 🥃 I have my privacy data, not intend to expose to public. Can I use chatgpt(❌), or others like LlaMA 2 (✅)?

When it comes to using AI models like `ChatGPT` or `LlaMA 2`, privacy is an important consideration. Here’s what you should know:

**ChatGPT(❌)**: The privacy policy of `ChatGPT` states that it may collect personal information from your messages, any files you upload, and any feedback you provide.

**LlaMA 2(✅)**: `LlaMA 2` **can handle sensitive and personal data like voice, text, and images**.

By hosting `LlaMA 2` in your environment, you can keep your private and sensitive information on your own ecosystem (on-premise or external cloud provider).

## 🤖 🥃 ChatGPT model

“ChatGPT 模型”旨在根据收到的输入文本生成对话响应。

## 🤖 🥃 Generative Pre-trained Transformer 3 (GPT-3)

## 🤖 🥃 Generative AI vs. Supervised AI

`生成式人工智能`（Generative AI）和`监督式人工智能`（Supervised AI）是两种不同的人工智能方法，具有独特的特点和应用。

`生成式人工智能`是指能够根据训练数据学习到的模式生成新内容的模型，例如文本、图片甚至音乐。这些模型学习训练数据的潜在分布，然后可以生成类似于训练数据的新样本。`生成式人工智能`模型通常使用深度学习和概率建模等技术来推断模式并创建新内容。`生成式人工智能`模型的例子包括像GPT这样的语言模型和生成对抗网络（GANs）这样的图像生成模型。

`监督式人工智能`则是使用带有标签的数据来训练模型。在监督学习中，模型被提供输入数据以及相应的正确输出标签，并根据这些带标签的训练数据来学习将输入映射到输出。模型然后通过这个映射来对未见过的数据进行预测。监督学习常用于分类、回归和物体识别等任务。`监督式人工智能`算法的例子包括支持向量机（SVM）、决策树和使用标记数据进行训练的神经网络。

总结一下，`生成式人工智能`专注于根据学习到的模式创建新内容，而`监督式人工智能`专注于使用带有标签的训练数据将输入映射到输出。这两种方法都有各自的优点和应用，选择哪种方法取决于具体的问题和可用的数据。

## 🤖 🥃 [localGPT](https://github.com/PromtEngineer/localGPT)

Chat with your documents on your local device using GPT models. No data leaves your device and 100% private. You can ingest documents and ask questions without an internet connection!

Built with **LangChain** and Vicuna-7B (+ alot more!) and InstructorEmbeddings

## 🤖 🥃 Integrate term into Web UI

- xterm.js
- tabby: Tabby is a popular terminal library for the web, built with Rust and WebAssembly. use `npm` or `yarn` to install it.

## 🤖 🥃 Integrate GPT into Web UI

- both Llama 2 and LangChain can work with databases like Elasticsearch or MongoDB as input datasets.
- Llama 2 and LangChain can be used to build a chatbot that can answer questions about a company's products and services.
- 是的，Llama 2和LangChain都可以与Elasticsearch或MongoDB等数据库作为输入数据集进行配合。
Llama 2是一种用于数据处理和分析的编程语言。它提供了各种内置的连接器，可以与不同的数据源进行交互，包括数据库。你可以使用适用于Elasticsearch或MongoDB的相应连接器来从这些数据库中读取数据，并使用Llama 2执行数据处理操作。
另一方面，LangChain是一种用于区块链智能合约的编程语言。虽然它主要关注区块链相关操作，但也可以与外部数据源进行交互，包括数据库。你可以使用LangChain中可用的适当库或模块连接到Elasticsearch或MongoDB，并为你的智能合约获取数据。
- **The input datasets for both Llama 2 and LangChain are typically in the form of structured data, often in JSON or CSV format**
- NLP: 自然语言处理
- Vector Storage: Tools like `FAISS`, `Chroma`, or `Elasticsearch` are often used to perform these similarity searches in vector space.

## 🥃  GTP-4 turbo

1. GPT-4 Turbo on OPENAI DevDay, and Elon Musk's Grok.
2. GPT-4 Turbo supports 128k context, price reduction, speed up acceleration, fully open APIs
3. 128k context, 300 pages
4. JSON, multi APIs calling, Seeds, logs
5. updating knowledge, 2023-04, 2024-09, upload docs to learn
6. DALLE3, Vision, TTS (via web or APIs)
7. Fine Tunning, customize (for enterprise)
8. 2w Token, Cost-effectiveness

- Make or Zapier Automation tools
- TTS (6)
- Whisper V3
- Custom Models
- Copyrights shields

## 🤖 n8n.io

`n8n` is a powerful, open-source workflow automation tool designed to help you automate tasks across different services.

## 🤖 GPT Store

## 🤖 Assistants AI, AI Agent
